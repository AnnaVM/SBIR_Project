{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project Proposal: SBIR award prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reminder from first proposal --> High level view:\n",
    "The Small Business Innovation Research (SBIR,  https://www.sbir.gov/) program relies on an award-based system to trigger high-tech innovation in small US companies. Many agencies (Departement of Agriculture, of Defense, ...) contribute to this fund. Two main phases structure the SBIR program: phase I (approx 150 000 dollars, 6 months) and phase II (approx 1 000 000 dollars for 2 years). To apply to phase II, companies must be phase I awardees. \n",
    "\n",
    "The predictive question I want to answer is: will your project make it to phase II?  \n",
    "The interpretative question I would like to address is: what features make you likely to be successful in applying to phase II?\n",
    "\n",
    "####Aim of this document --> establish the presence of a signal in the data:\n",
    "This document follows the pipeline I developped to evaluate a simple predictive model (Logistic Regression) on a small dataset. In the end, this exploratory work shows that the simple predictor outperforms a baseline predictor (one that randomly predicts success or failure with the baseline probability of the training set). Further ideas to increase predictive power are also listed.\n",
    "\n",
    "Data and code I used for this proposal can be found on GitHub, at https://github.com/AnnaVM/SBIR_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "#from code in the GitHub Repro (https://github.com/AnnaVM/SBIR_Project)\n",
    "from prepare_data import subset_data\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Loading a subset of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this proposal, I worked only on a subset of my data (data from years 2012 to 2015, with one specific agency, the Department of Defense 'dod'). \n",
    "- A first converter allowed me to go from .xlsx files to .csv files. (not shown here, available on the GitHub Repo)\n",
    "- A second function allows me to work on the subset (code and csv files are available on the GitHub Repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015-12-14_award_export_10001TO15000.csv', '2015-12-14_award_export_1TO5000.csv', '2015-12-14_award_export_5001TO10000.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "prepare_data.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  .apply(lambda x: is_in_phase_I_to_II(x, phase_I_to_II))\n"
     ]
    }
   ],
   "source": [
    "df = subset_data('dod', 2012, '/Users/AnnaVMS/Desktop/test2')\n",
    "#update path according to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of phase I projects considered:  1016\n"
     ]
    }
   ],
   "source": [
    "print 'number of phase I projects considered: ',len(df.to_phase_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of phase I projects with successful application to phase II:  305\n"
     ]
    }
   ],
   "source": [
    "print 'number of phase I projects with successful application to phase II: ',sum(df.to_phase_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of phase I projects without a phase II:  711\n"
     ]
    }
   ],
   "source": [
    "print 'number of phase I projects without a phase II: ',len(df.to_phase_II)-sum(df.to_phase_II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information in the database: \n",
      "Index([u'index', u'Company', u'Award Title', u'Agency', u'Branch', u'Phase',\n",
      "       u'Program', u'Agency Tracking #', u'Contract', u'Award Start Date',\n",
      "       u'Award Close Date', u'Solicitation #', u'Solicitation Year',\n",
      "       u'Topic Code', u'Award Year', u'Award Amount', u'DUNS',\n",
      "       u'Hubzone Owned', u'Socially and Economically Disadvantaged',\n",
      "       u'Woman Owned', u'# Employees', u'Company Website', u'Address1',\n",
      "       u'Address2', u'City', u'State', u'Zip', u'Contact Name',\n",
      "       u'Contact Title', u'Contact Phone', u'Contact Email', u'PI Name',\n",
      "       u'PI Title', u'PI Phone', u'PI Email', u'RI Name', u'RI POC Name',\n",
      "       u'RI POC Phone', u'Research Keywords', u'Abstract', u'to_phase_II'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#quick overview of the dataset\n",
    "print 'information in the database: \\n',df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The last column 'to_phase_II' gives information on whether a phase II was obtained. It will be used as the label to predict in my model\n",
    "- Features can be choosen in the rest of the columns (here for instance: 'Solicitation Year', 'Award Amount', 'Hubzone Owned', 'Socially and Economically Disadvantaged', 'Woman Owned', '# Employees') or engineered (from 'Abstract', I made 'Abstract Length'--simple character count-- and 'Topic of Abstract' --through NMF topic modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###defining a first model, based on this subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#defining a training and testing set (through indices)\n",
    "kf = KFold(1016,5, shuffle=True)\n",
    "kf_iterator = kf.__iter__()\n",
    "train_index, test_index = kf_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####The Pipeline:\n",
    "1- Processing the text of the Abstract of submissions\n",
    "- tfidf vectorization of the text (5000 words in the dictionary, default tokenization of sklearn)\n",
    "- topic modeling: NMF (5 components, no optimization done here)\n",
    "\n",
    "2- Preparing data for model\n",
    "- using dummy variables for topics\n",
    "- mapping Y/N to 1/0\n",
    "- getting the abstract length in characters\n",
    "\n",
    "3- Running the Logistic Regression\n",
    "- Standard scaling of the data\n",
    "- Logistic Regression (lasso regularization)\n",
    "--> outputs the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_test = Model(df, train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step 1\n",
    "model_test.process_text('Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step 2\n",
    "model_test.prepare_LogReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73399014778325122, 0.58584468270066636, 0.73529411764705888)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step 3\n",
    "model_test.perform_LogReg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The first score is the accuracy of the Logistic Classifier on the training set;\n",
    "- the second score is the accuracy of the baseline predictor (one that randomly predicts success or failure with the baseline probability of the training set),\n",
    "- the third score gives the accuracy of the Logistic Classifier on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Some information on the models (coefficients from LogReg and topics from NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeffs</th>\n",
       "      <th>criterion:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009701</td>\n",
       "      <td>topic 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.074706</td>\n",
       "      <td>topic 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050049</td>\n",
       "      <td>topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.162837</td>\n",
       "      <td>topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135534</td>\n",
       "      <td>Solicitation Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.667513</td>\n",
       "      <td>Award Amount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050143</td>\n",
       "      <td>Hubzone Owned as_int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.139014</td>\n",
       "      <td>Socially and Economically Disadvantaged as_int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.084231</td>\n",
       "      <td>Woman Owned as_int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.030715</td>\n",
       "      <td># Employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.795579</td>\n",
       "      <td>Abstract Length</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      coeffs                                      criterion:\n",
       "0   0.009701                                         topic 4\n",
       "1  -0.074706                                         topic 3\n",
       "2   0.050049                                         topic 2\n",
       "3  -0.162837                                         topic 1\n",
       "4   0.000000                                         topic 0\n",
       "5   0.135534                               Solicitation Year\n",
       "6   0.667513                                    Award Amount\n",
       "7   0.050143                            Hubzone Owned as_int\n",
       "8  -0.139014  Socially and Economically Disadvantaged as_int\n",
       "9   0.084231                              Woman Owned as_int\n",
       "10 -0.030715                                     # Employees\n",
       "11  0.795579                                 Abstract Length"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the coefficients in the Logisitic Regression (lasso regularized)\n",
    "pd.DataFrame( {'criterion:': model_test.list_columns[:-1], \n",
    "               'coeffs': model_test.model_LogReg.coef_[0]} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'high' u'power' u'materials' u'laser' u'phase' u'technology' u'design'\n",
      " u'low' u'applications' u'energy']\n",
      "[u'data' u'information' u'network' u'security' u'analysis' u'cyber'\n",
      " u'networks' u'quot' u'satellite' u'software']\n",
      "[u'model' u'models' u'plume' u'modeling' u'simulation' u'software'\n",
      " u'effects' u'missile' u'3d' u'damage']\n",
      "[u'training' u'learning' u'rpa' u'adaptive' u'performance' u'game'\n",
      " u'trainee' u'based' u'tool' u'simulation']\n",
      "[u'sensor' u'radar' u'sensors' u'target' u'tracking' u'space' u'detection'\n",
      " u'objects' u'surveillance' u'processing']\n"
     ]
    }
   ],
   "source": [
    "#topics defined with NMF:\n",
    "for i in xrange(5):\n",
    "    print model_test.get_top_n_words_for_topic(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Further Work\n",
    "\n",
    "Other, easy but time-consuming developments\n",
    "- adding other features (State...)\n",
    "- vectorizing and topic modeling for other text inputs (Title, Keywords, Contact Title...)\n",
    "- adding further company information\n",
    "- tuning regularization on Logistic Regression\n",
    "- running other models (getting feature importance with Random Forest for interpretation, trying to increase predictive power with SVM)\n",
    "\n",
    "Other, harder, routes:\n",
    "- developping a sentiment analysis (very technical, very assured, very detail-oriented, very goal-oriented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Bibliography\n",
    "A paper featured in Kaggle, as a source inspiration\n",
    "- http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
